**Class:** [[CIS*2500]]
**Date:** 01-04-2025
**Topics:** [[Algorithms]], [[Generational Algorithms]]

## Time Complexity
*Time Complexity* estimates how an algorithm or code performs regardless of the kind of machine it runs on. 

To find the *time complexity* of any code, "count" the number of operations performed by your code. This way you can *estimate* how the runtime of your code grows as the *input size* $n$ is *increased*.

This estimated value is typically represented using *Big-O notation*, where $O$ is the worst-case scenario of how fast (or slow) the runtime of your code grows as the size of input $n$ grows.

$$O(1) < O(\log{n})<O(n)<O(n \log{n})<O(n^2)<...<O(2^n)$$
